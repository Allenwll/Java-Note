# 同步机制和ThreadLocal

> 1.同步机制是以时间换空间
> 
> > 提供一份变量，让不同的线程排队访问
> 
> 2.ThreadLocal是以空间换时间
> 
> > 为每一个线程都提供了一份变量，因此可以同时访问而互不影响

# synchronized

> JDK1.5之前只能用其来实现同步
> 
> 属于独占锁，悲观锁的一种、性能不高
> 
> > 会导致其他需要该资源的线程挂起，直到前面的线程执行完毕释放所资源
> > 
> > 对应的乐观锁的原理是每次不加锁去执行某项操作，如果发生冲突则失败并重试，直到成功为止，其实本质上不算锁，所以很多地方也称之为自旋 主要机制是CAS
> 
> 基于JVM保证数据同步

### 实现方案  JVM

> 应用层含义:把任意一个非NUll的对象当做锁
> 
> > 锁住的是对象的实例[this],当作用于静态方法时,锁住的是对应的代码块
> > 
> > HotSpot JVM实现中，还有一个名字叫做对象监视器
> 
> 当多个线程一起访问某个对象监视器时,会将这些请求存储在不同的容器中
> 
> > Contention List:竞争队列，所有请求锁的线程首先会被放在其中
> > 
> > > ContentionList是一个虚拟队列，只有Node以及对应的Next指针组成,并没有Queue的数据结构
> > > 
> > > 每次新加入的Node会在队头进行，通过CAS改变第一个节点为新增节点,同时新增阶段的next指向后续节点,而取数据都在队列尾部进行
> > 
> > Entry List:有资格成为候选资源的线程被移动至其中
> > 
> > > JVM每次从队列的尾部取出一个数据用于锁竞争候选者(OnDeck)
> > > 
> > > 但是并发情况下,ContentionList会被大量的并发线程进行CAS访问,为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程
> > 
> > Wait Set:调用wait方法被阻塞的线程被放置在这里
> > 
> > > 如果Owner线程被wait方法阻塞,则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进入EntryList中
> > 
> > OnDeck:任意时刻最多只有一个线程正在竞争锁资源
> > 
> > > OnDeck线程获取到锁资源后会点成Owner线程，而没有得到锁资源的仍停留在EntryList中
> > 
> > Owner:当前已经获取到锁资源线程
> > 
> > > Owner线程会在unlock时,将ContentionList中的部分线程迁移到EntryList,指定EntryList的某个线程为OnDeck线程(一般是最先进去的那个线程）
> > > 
> > > Owner线程并不直接把锁传递给OnDeck线程,而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁，虽然牺牲了一些公平性，但是能极大提升系统的吞吐量，在JVM中，这种选择行为称之为"竞争切换"
> > 
> > !Owner:当前释放锁的线程

### 阻塞

> > > 处于ContentList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的,(Linux下采用pthread_mutex_lock内核函数实现)
> > > 
> > > 该线程被阻塞后则进入内核调度状态,会导致系统在用户和内核之间进行来回切换，严重影响锁的性能。缓解方案是自旋锁

### 自旋锁

> 如果Owner线程能在很短时间内释放锁资源,那么等待竞争锁的线程可以稍微等一等(自旋)而不是立即阻塞
> 
> 当Owner线程释放锁后可立即获取锁,进而避免用户线程和内核的切换。
> 
> 但是Owner可能执行的时间会超过设定的阈值,争用线程在一定时间内还是获取不到锁,这时争用线程会停止自旋进入阻塞状态
> 
> **基本思路就是先自旋等待一段时间看能否成功获取，如果不成功再执行阻塞,尽可能减少阻塞的可能性，对于占用锁时间比较短的代码块而言性能可得到大幅度提升**
> 
> > 其实就是执行几个空方法,稍微等一等，也许是一段时间的循环，也许是几行空的汇编指令，其目的是为了占着CPU的资源不释放,等到获取到锁立即进行处理

#### 自旋周期

> _如果自旋执行时间太长，会有大量线程处于自旋状态占用CPU资源，影响整体系统的性能_
> 
> 基本一个线程上下文切换到时间是最佳的一个时间,对CPU负荷做的优化:
> 
> > 1.如果平均负载小于CPUs则一直自旋
> > 
> > 2.如果有超过(CPUs/2)个线程个正在自旋，则后来线程直接阻塞
> > 
> > 3.如果自旋中的线程发现Owner发生了变化则延迟自旋时间或进入阻塞
> > 
> > 4.如果CPU处于节电模式则停止自旋
> > 
> > 5.自旋时间的最坏情况是CPU的存储延迟
> > 
> > 6.自旋时会适当放弃线程优先级的差异

### 偏向锁 (JVM6引入)

> Synchronized在线程进入ContentionList时，等待的线程就通过自旋先获取锁,如果获取不到就进入ContentionList,对于已经进入队列的线程是不公平的
> 
> 自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源
> 
> 偏向锁用于解决无竞争下面锁的性能问题
> 
> > 锁都是可重入的，即已经获取锁的线程可以多次锁定/解锁监视对象
> > 
> > 每次加锁解锁都采用CAS(Compare And Swap)操作，则CAS会引发本地延迟
> > 
> > 因此偏向锁希望线程一旦获取到监视对象后，之后让监视对象偏向这个锁,进而避免多次CAS操作,降低缓存一致性流量

### CAS为什么会引发本地延迟:

> **多核处理架构  SMP**
> 
> > 多核CPU会共享一条系统总线，靠总线和主存通讯，但是每个CPU又有自己的一级缓存，而CAS是一条原子指令，其作用是让CPU比较如果相同则进行数据更新,而这些是基于硬件实现的[JVM只封装了硬件的汇编调用]() 
> > 
> > 多核运算时,由于线程切换，很有可能第二次取值是在另外一个CPU上执行的，CAS要保证数据一致性，恰好会引发比较多的一致性流量
> > 
> > > 假设Core1和Core2把对应的某个值加载到自己的一级缓存时,某个时刻Core1更新了这个数据并通过总线通知主存,此时Core2的一级缓存中的数据就失效了，他需要从主存中重新加载一次到以及缓存中，大家通过总线通讯被称为**一致性流量**
> > > 
> > > 总线的通讯能力有限，当缓存一致性流量过大时,总线会成为瓶颈，而当Core1和Core2的数据再次一致时,被称为**缓存一致性**
> > 
> > 如果有很多线程共享一个对象，当某个线程成功执行一次CAS时为引发**总线风暴**,这就是本地延迟
> > 
> > 并不是所有的CAS都会引发总线风暴,这和**缓存一致性协议**有关
> > 
> > 偏向锁的引入带来了另一个问题，很多线程竞争使用中，如果一个线程持有偏向锁,另一个线程想争用偏向锁,拥有者想释放这个偏向锁,释放会带来而外的性能开销,但总体来说好处大于CAS的代价

# Lock

> JDK1.5之后提供
> 
> 性能比synchronized高
> 
> 基于硬件层面，依赖特殊的CPU指令实现数据同步

## 实现方案

> 纯Java实现,与底层JVM无关 java.util.concurrent.locks
> 
> 实现类有ReentrantLock、ReadWriteLock(实现类ReentrantReadWirteLock)其实现都依赖java.util.concurrent.AbstractQueueSynchronizer类(AQS)

## AQS

> 是Lock和Excutor实现的基础,支持取锁和释放锁两个操作

### 获取锁:

> 首先判断当前状态是否允许获取锁,是则获取,否则阻塞操作或获取失败
> 
> > 就是说如果是独占锁就可能阻塞，如果是共享锁就可能失败
> > 
> > 如果是阻塞线程，那么线程需要进入阻塞队列
> > 
> > 当状态为允许获取锁时就修改状态，并且如果进了队列就从队列中移除

### 释放锁:

> 修改状态位
> 
> 如果有线程是因为状态位阻塞的话,就唤醒队列中的一个或者更多线程

### 支持获取和释放的两个操作需要满足下列条件:

> 1.状态位必须是原子操作的
> 
> > 原子操作状态位 CAS   
> > 
> > JDK中也是通过一个32bit的整数位进行CAS操作实现的
> 
> 2.阻塞和唤醒线程
> 
> > JDK1.5之前的API中没有阻塞一个线程，然后在将来的某个时刻唤醒它
> > 
> > JDK1.5之后利用JNI在LockSupport这个类中实现了相关的特性
> 
> 3.一个有序的队列，用于支持锁的公平性
> 
> > 采用C L H对来解决所有队列问题

## ReentrantLock的调用过程:

> 1.把所有的Lock都委托给Sync类进行处理,该类继承自AQS
> 
> 2.其中Sync又有两个final static的子类NonfairSync和FairSync用于支持非公平锁(默认)和公平锁
> 
> 1).AQS抽象了大多数Lock的功能，而只把tryAcquire(int)委托给子类进行多态实现，tryAcquire用于判断线程是否都能够获取锁，无论成功与否，AQS都将处理后续流程
> 
> 2).简单来讲,AQS会把所有请求锁的线程组成一个CLH的队列。当一个线程执行完毕释放锁Lock.unlock()时，AQS会激活后继节点，正在执行的线程不在队列当中，而那些等待的线程全部处于阻塞状态
> 
> > 最终是通过LockSupport.park()实现的，而底层是调用sum.misc.Unsafe.park()本地方法,再进一步，HotSpot在Linux中通过调用pthread_mutex_lock函数把线程交给系统内核进行阻塞

### CLH队列

> 也是虚拟队列[原生的CLH队列用于自旋锁,JUC将其改造为阻塞锁]()
> 
> 当获取锁失败时不立即进行阻塞，而是先自旋一端时间看看是否能获取锁，这对那些已在阻塞队列里的线程不公平(非公平锁的实现，公平锁通过有序队列强制线程顺序进行),但会极大提升吞吐量.
> 
> 如果自旋还是获取失败，则创建一个节点加入队列尾部(CAS)
> 
> 并发对队尾CAS操作有可能回发生失败,AQS是采用自旋循环的方法，直到CAS成功

### 锁实现细节

> 锁的实现依赖于lock()方法
> 
> Lock方法首先是调用acquire(int)方法，不管是公平锁还是非公平锁
> 
> Acquire()犯法默认先调用tryAcuire(int)方法,此时两种锁实现方式不一致
> 
> > Sync.NonfairSync.TryAcquire非公平锁
> > 
> > nonfairTryAcquire方法是lock方法简介调用的第一个方法,每次调用都会先调用该方法
> > 
> > 该方法首先判断当前线程状态,如果状态为0则说明没有线程正在竞争锁
> > 
> > > 通过CAS将状态设为acquires(独占锁的acquires为1)，后续每次重入+1，每次unloock都会-1，当其为0时则释放锁资源
> > > 
> > > 好处是并发访问时可能多个线程同时检测到为0
> > > 
> > > 此时compareAndSetState(0,acquires)设置可以预见如果当前线程CAS成功,则其他线程都不会再成功,也就默认当前线程获取了锁，直接作为running线程，无需进入等待队列
> > 
> > 如果线程状态为不为0,首先判断获取的线程是不是当前线程
> > 
> > 如果是当前线程则表明为锁重入,继续+1,修改state状态,此时并无锁竞争也非CAS,所以实现了偏向锁