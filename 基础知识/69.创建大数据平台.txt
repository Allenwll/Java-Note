
	从平台部署和数据分析过程分：

1.Linux系统安装

	一般使用开源版的Redhat系统--CentOS作为底层平台.为了提供稳定的硬件基础,在给硬盘做RAID和挂载数据存储节点的时,需要按情况配置
	
	例如,可以选择给HDFS的namenode做RAID2以提高其稳定性,将数据存储与操作系统分别放置在不同硬盘上,以确保操作系统的正常运行
	
2.分布式计算平台/组件安装 

	目前国内外的分布式系统的大多使用的是Hadoop系列开源系统
	
	Hadoop的核心是HDFS,一个分布式的文件系统.在其基础上常用的组件有Yarn、Zookeeper、Hive、Hbase、Sqoop、Impala、ElasticSearch、Spark等
	
		组件功能: 11
			
			分布式集群的资源管理器一般用Yarn『全名是Yet Another Resource Negotiator』
			
			常用的分布式数据数据仓库有Hive、Hbase
			
				Hive可以用SQL查询『但效率略低』
				
				Hbase可以快速『近实时』读取行
				
			外部数据库导入导出需要用到Sqoop
				
				Sqoop将数据从Oracle、MySQL等传统数据库导入Hive或Hbase
				
			Zookeeper是提供数据同步服务,Yarn和Hbase需要它的支持
			
			Impala是对Hive的一个补充,可以实现高效的SQL查询
			
			ElasticSearch是一个分布式的搜索引擎
			
			针对分析,目前最火的是Spark『此处忽略其他,如基础的MapReduce 和 Flink』
			
			Spark在core上面有ML lib,Spark Streaming、Spark QL和GraphX等库,可以满足几乎所有常见数据分析需求
			
3.数据导入
			
	Sqoop可以将数据从文件或者传统数据库导入到分布式平台『一般主要导入到Hive,也可将数据导入到Hbase』
	
4.数据分析

	一般包括两个阶段:数据预处理和数据建模分析
	
	数据预处理:
	
		是为后面的建模分析做准备,主要工作时从海量数据中提取可用特征,建立大宽表
		
		这个过程可能会用到Hive SQL,Spark QL和Impala
		
	数据建模分析:
		
		是针对预处理提取的特征/数据建模,得到想要的结果
		
		这一块最好用的是Spark
		
		常用的机器学习算法,如朴素贝叶斯、逻辑回归、决策树、神经网络、TFIDF、协同过滤等,都已经在ML lib里面,调用比较方便

5、结果可视化及输出API  

	可视化一般式对结果或部分原始数据做展示
	
	一般有两种情况,行数据展示,和列查找展示.
	
		要基于大数据平台做展示,会需要用到ElasticSearch和Hbase
		
		Hbase提供快速『ms级别』的行查找
		
		ElasticSearch可以实现列索引,提供快速列查找
		
		
平台搭建主要问题:

	1、稳定性 Stability   
	
		理论上来说,稳定性是分布式系统最大的优势,因为它可以通过多台机器做数据及程序运行备份以确保系统稳定
		
		但也由于大数据平台部署于多台机器上,配置不合适,也可能成为最大的问题

			曾经遇到的一个问题是Hbase经常挂掉,主要原因是采购的硬盘质量较差
		
			硬盘损坏有时会到导致Hbase同步出现问题,因而导致Hbase服务停止
		
			由于硬盘质量较差,隔三差五会出现服务停止现象,耗费大量时间
		
		结论：大数据平台相对于超算确实廉价,但是配置还是必须高于家用电脑的
		
	2、可扩展性 Scalability   
	
		如何快速扩展已有大数据平台,在其基础上扩充新的机器是云计算等领域应用的关键问题
		
		在实际2B的应用中,有时需要增减机器来满足新的需求
		
		如何在保留原有功能的情况下,快速扩充平台是实际应用中的常见问题

目前国内和国际上已有多家公司提供大数据平台搭建服务

国外有名的公司有Cloudera,Hortonworks,MapR等

国内也有华为、明略数据、星环等

对于一些本身体量较小或者目前数据量积累较少的公司,个人认为没有必要搭建这一套系统,暂时先租用AWS和阿里云就够了

对于数据量大,但数据分析需求较简单的公司,可以直接买Tableau,Splunk,HP Vertica,或者IBM DB2等软件或服务即可
