		Hadoop [hædu:p] 项目的创建者是Doug Cutting
		
1.由来;

	“这个名字是我孩子给一个棕黄色的大象玩具命名的,我的命名标准就是简短,容易发音和拼写,没有太多的意义,并且不会被用于别处.小孩子恰恰是这方面的高手.”
		
2.定义:

	Hadoop是一个由Apache基金会所开发的分布式系统基础架构
	
		分布式系统(distributed system)是建立在网络之上的软件系统.正是因为软件的特性,所以分布式系统具有高度的内聚性和透明性
		
		用户可以在不了解分布式底层细节的情况下,开发分布式程序.充分利用集群的威力进行高速运算和存储
		
	Hadoop实现了一个分布式文件系统(Hadoop Distributed File System),简称HDFS
	
		HDFS有高容错性的特点,并且设计用来部署在低廉的(low-cost)硬件上
		
		而且它提供高吞吐量(high throughput)来访问应用程序的数据,适合那些有着超大数据集(large data set)的应用程序
		
		HDFS放宽了(relax)POSIX的要求,可以以流的形式访问(streaming access)文件系统中的数据
		
	Hadoop的框架最核心的设计就是：HDFS和MapReduce.HDFS为海量的数据提供了存储,则MapReduce为海量的数据提供了计算
	
3.优点:

	Hadoop是一个能够对大量数据进行分布式处理的软件框架. Hadoop以一种可靠、高效、可伸缩的方式进行数据处理
	
	Hadoop 是可靠的,因为它假设计算元素和存储会失败,因此它维护多个工作数据副本,确保能够针对失败的节点重新分布处理
	
	Hadoop 是高效的,因为它以并行的方式工作,通过并行处理加快处理速度
	
	Hadoop 还是可伸缩的,能够处理PB级数据.
	
	Hadoop 依赖于社区服务,因此它的成本比较低,任何人都可以使用
	 
		高可靠性  按位存储和处理数据的能力强
		
		高扩展性  在可用的计算机集簇间分配数据并完成计算任务的,这些集簇可以方便地扩展到数以千计的节点中
		
		高效性	能够在节点之间动态地移动数据,并保证各个节点的动态平衡,因此处理速度非常快
		
		高容错性 能够自动保存数据的多个副本,并且能够自动将失败的任务重新分配
		
		低成本 与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比,hadoop是开源的,项目的软件成本因此会大大降低.
		
4.核心架构:

	Hadoop 由许多元素构成.其最底部是 Hadoop Distributed File System(HDFS),它存储 Hadoop 集群中所有存储节点上的文件
	
	HDFS(对于本文)的上一层是MapReduce引擎,该引擎由 JobTrackers 和 TaskTrackers 组成
	
	通过对Hadoop分布式计算平台最核心的分布式文件系统HDFS、MapReduce处理过程
	
	以及数据仓库工具Hive和分布式数据库Hbase的介绍,基本涵盖了Hadoop分布式平台的所有技术核心
	
5.HDFS 

	对外部客户机而言,HDFS就像一个传统的分级文件系统.可以创建、删除、移动或重命名文件,等等.但是 HDFS 的架构是基于一组特定的节点构建的
	
	这是由它自身的特点决定的.这些节点包括 NameNode(仅一个),它在 HDFS 内部提供元数据服务;
	
	DataNode它为 HDFS 提供存储块.由于仅存在一个 NameNode,因此这是 HDFS 的一个缺点(单点失败)
	
	存储在 HDFS 中的文件被分成块,然后将这些块复制到多个计算机中(DataNode)
	
	这与传统的 RAID 架构大不相同.块的大小(通常为 64MB)和复制的块数量在创建文件时由客户机决定
	
	NameNode 可以控制所有文件操作.HDFS 内部的所有通信都基于标准的 TCP/IP 协议
	
6.NameNode 

	是一个通常在HDFS实例中的单独机器上运行的软件.它负责管理文件系统名称空间和控制外部客户机的访问
	
	NameNode 决定是否将文件映射到 DataNode 上的复制块上
	
		对于最常见的 3 个复制块
	
		第一个复制块存储在同一机架的不同节点上
		
		最后一个复制块存储在不同机架的某个节点上
	
	实际的 I/O事务并没有经过 NameNode,只有表示 DataNode 和块的文件映射的元数据经过 NameNode
	
	当外部客户机发送请求要求创建文件时,NameNode 会以块标识和该块的第一个副本的 DataNode IP 地址作为响应
	
	这个 NameNode 还会通知其他将要接收该块的副本的 DataNode
	
	NameNode 在一个称为 FsImage 的文件中存储所有关于文件系统名称空间的信息
	
	这个文件和一个包含所有事务的记录文件(这里是 EditLog)将存储在 NameNode 的本地文件系统上
	
	FsImage 和 EditLog 文件也需要复制副本,以防文件损坏或 NameNode 系统丢失
	
	NameNode本身不可避免地具有SPOF(Single Point Of Failure)单点失效的风险,主备模式并不能解决这个问题
	
	通过Hadoop Non-stop namenode才能实现100% uptime可用时间
	
7.DataNode

		DataNode 也是一个通常在 HDFS实例中的单独机器上运行的软件
		
		Hadoop 集群包含一个 NameNode 和大量 DataNode
		
		DataNode 通常以机架的形式组织,机架通过一个交换机将所有系统连接起来
		
		Hadoop 的一个假设是：机架内部节点之间的传输速度快于机架间节点的传输速度
		
8.文件操作

	HDFS 并不是一个万能的文件系统.它的主要目的是支持以流的形式访问写入的大型文件
	
	如果客户机想将文件写到 HDFS 上,首先需要将该文件缓存到本地的临时存储.如果缓存的数据大于所需的 HDFS 块大小,创建文件的请求将发送给 NameNode
	
	NameNode 将以 DataNode 标识和目标块响应客户机,同时也通知将要保存文件块副本的 DataNode
	
	当客户机开始将临时文件发送给第一个 DataNode 时,将立即通过管道方式将块内容转发给副本 DataNode
	
	客户机也负责创建保存在相同 HDFS名称空间中的校验和(checksum)文件
	
	在最后的文件块发送之后,NameNode 将文件创建提交到它的持久化元数据存储(在 EditLog 和 FsImage 文件)
	
9.Linux集群

	分布式：一个业务分拆多个子业务,部署在不同的服务器上
	
	集群：同一个业务,部署在多个服务器上
	
	Hadoop 框架可在单一的 Linux 平台上使用(开发和调试时),官方提供MiniCluster作为单元测试使用,不过使用存放在机架上的商业服务器才能发挥它的力量
	
	这些机架组成一个 Hadoop 集群.它通过集群拓扑知识决定如何在整个集群中分配作业和文件
	
	Hadoop 假定节点可能失败,因此采用本机方法处理单个计算机甚至所有机架的失败
	
10.MapReduce与Hadoop之比较

		Hadoop是一种分布式数据和计算的框架
		
			它很擅长存储大量的半结构化的数据集
			
			数据可以随机存放,所以一个磁盘的失败并不会带来数据丢失
			
			Hadoop也非常擅长分布式计算——快速地跨多台机器处理大型数据集合
		
		MapReduce是处理大量半结构化数据集合的编程模型
			
			编程模型是一种处理并结构化特定问题的方式
			
				例如,在一个关系数据库中,使用一种集合语言执行查询,如SQL.告诉语言想要的结果
				
					并将它提交给系统来计算出如何产生计算.还可以用更传统的语言(C++,Java),一步步地来解决问题.
				
				这是两种不同的编程模型,MapReduce就是另外一种

11.集群系统

	Google的数据中心使用廉价的Linux PC机组成集群,在上面运行各种应用.即使是分布式开发的新手也可以迅速使用Google的基础设施
	
	核心组件是3个：
		
		GFS(Google File System)
		
			一个分布式文件系统,隐藏下层负载均衡,冗余复制等细节,对上层程序提供一个统一的文件系统API接口
			
			Google根据自己的需求对它进行了特别优化,包括：
			
				超大文件的访问
				
				读操作比例远超过写操作
				
				PC机极易发生故障造成节点失效等
				
			GFS把文件分成64MB的块,分布在集群的机器上,使用Linux的文件系统存放
			
			同时每块文件至少有3份以上的冗余.中心是一个Master节点,根据文件索引,找寻文件块
		
		MapReduce
		
			Google发现大多数分布式运算可以抽象为MapReduce操作
			
			Map是把输入Input分解成中间的Key/Value对
			
			Reduce把Key/Value合成最终输出Output
			
			这两个函数由程序员提供给系统,下层设施把Map和Reduce操作分布在集群上运行,并把结果存储在GFS上
		
		BigTable
			
			一个大型的分布式数据库,这个数据库不是关系式的数据库.像它的名字一样,就是一个巨大的表格,用来存储结构化的数据			
				
12.子项目

	Hadoop Common: 在0.20及以前的版本中,包含HDFS、MapReduce和其他项目公共内容,从0.21开始HDFS和MapReduce被分离为独立的子项目,其余内容为Hadoop Common
	
	HDFS: Hadoop分布式文件系统(Distributed File System) － HDFS (Hadoop Distributed File System)
	
	MapReduce：并行计算框架,0.20前使用 org.apache.hadoop.mapred 旧接口,0.20版本开始引入org.apache.hadoop.mapreduce的新API
	
	HBase: 类似Google BigTable的分布式NoSQL列数据库.(HBase和Avro已经于2010年5月成为顶级 Apache 项目)
	
	Hive：数据仓库工具,由Facebook贡献
	
	Zookeeper：分布式锁设施,提供类似Google Chubby的功能,由Facebook贡献
	
	Avro：新的数据序列化格式与传输工具,将逐步取代Hadoop原有的IPC机制
	
	Pig: 大数据分析平台,为用户提供多种接口	
	
	Ambari：Hadoop管理工具,可以快捷的监控、部署、管理集群
	
	Sqoop：于在HADOOP与传统的数据库间进行数据的传递
	
13.应用

	分布式集群的资源管理器一般用Yarn,『全名是Yet Another Resource Negotiator』
	
	常用的分布式数据数据『仓』库有Hive、Hbase
	
		Hive可以用SQL查询『但效率略低』,Hbase可以快速『近实时』读取行
		
	外部数据库导入导出需要用到Sqoop
		
		Sqoop将数据从Oracle、MySQL等传统数据库导入Hive或Hbase
		
	Zookeeper是提供数据同步服务,Yarn和Hbase需要它的支持
	
	Impala是对hive的一个补充,可以实现高效的SQL查询
	
	ElasticSearch是一个分布式的搜索引擎
	
	针对分析,目前最火的是Spark『此处忽略其他,如基础的MapReduce 和 Flink』
	
	Spark在core上面有ML lib,Spark Streaming、Spark QL和GraphX等库,可以满足几乎所有常见数据分析需求

14.Hadoop项目结构
	
	HDFS	 	分布式文件系统

	MapReduce	分布式并行编程模型

	YARN		资源管理和调度器
	
	Tez			运行在YARN之上的下一代Hadoop查询处理框架
	
	Hive		Hadoop上的数据仓库
	
	HBase		Hadoop上的菲关系型的分布式数据库
	
	Pig			一个基于Hadoop的大规模数据分析平台,提供类似SQL的查询语言Pig Latin
	
	Sqoop		用于在Hadoop与传统数据库之间进行数据传递
	
	Oozie		Hadoop上的工作流管理系统
	
	Zookeeper	提供分布式协调一致性服务
	
	Storm		流计算框架
	
	Flume		一个高可用的、高可靠的、分布式的海量日志采集、聚合和传输的系统
	
	Ambari		Hadoop快速部署工具,支持Apache Hadoop集群的供应、管理和监控
	
	Kafka		一种高吞吐量的分布式发布订阅消息系统,可以处理消费者规模的网站中的所有动作流数据
	
	Spark		类似于Hadoop MapReduce的基于内存的通用并行计算框架
	